{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9eea36",
   "metadata": {},
   "source": [
    "load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c43e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard packages\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "#plot packages\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "\n",
    "#package to create date-time objects\n",
    "import datetime as dt\n",
    "\n",
    "#performance measures\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from IPython.utils import io\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def _naive_forecasting(actual: np.ndarray, seasonality):\n",
    "    return actual[:-seasonality]\n",
    "\n",
    "def mean_absolute_scaled_error(actual: np.ndarray, predicted: np.ndarray, seasonality):\n",
    "    #Baseline (benchmark) is computed with naive forecasting shifted bu seasonality\n",
    "    return mean_absolute_error(actual, predicted) / mean_absolute_error(actual[seasonality:], _naive_forecasting(actual, seasonality))\n",
    "\n",
    "def mean_directional_accuracy(y, y_hat):\n",
    "    #Mean Directional Accuracy\n",
    "    return np.mean(np.sign(y.diff()[1:]) == np.sign(y_hat.diff()[1:]))\n",
    "    # the reason the two diffrence are diffrentely computed is because y is inputed as dataframe column but yhat is a array. \n",
    "    #If this is diffrent then change.\n",
    "    \n",
    "#RF packages\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# import random \n",
    "import random\n",
    "\n",
    "#prophet packages\n",
    "from prophet import Prophet\n",
    "\n",
    "#LSTM packages\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "#SARIMAX packages\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import pmdarima as pm                       \n",
    "import warnings\n",
    "from itertools import product\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c1b700",
   "metadata": {},
   "source": [
    "First we load the dataset, then we transform the date variable to date-time formate and change the column names of the date and target variable to ds and y. Then we drop the AvgSerice variable as we do not which to use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63ece75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Britt\\Documents\\DataAnalyse\\data\\half_hour.txt', sep=\"\\t\")\n",
    "df.date = pd.date_range(df.date[0] , periods = len(df.date), freq='30min')\n",
    "df.rename(columns={'date' : 'ds', 'count' : 'y'}, inplace=True)\n",
    "df.drop(['AvgService'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd943e11",
   "metadata": {},
   "source": [
    "For m=48 this model is unable to run do to memory problems, therefore we need to aggregate the data to hourly to decrease the seasonality cycle length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25aa8dd",
   "metadata": {},
   "source": [
    "To resample the data we first have to make the data-time variable the index on which is resampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ead123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "df.set_index('ds', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a9e421",
   "metadata": {},
   "source": [
    "Then we create a new dataframe that has the same columns as df except for kperiod, this is the half-hour index and is thus irrelevant in the new set and is thus droped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444a5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSARIMAX=pd.DataFrame(columns=df.columns)\n",
    "dfSARIMAX=dfSARIMAX.drop('kperiod', axis = 1)\n",
    "dfSARIMAX['y']=df.resample('H').sum().y\n",
    "dfSARIMAX[['irregular', 'holiday', 'DeliverD1', 'DeliverD7',\n",
    "       'DeliverD14', 'DeliverD21', 'Bill1', 'Bill7', 'Bill14', 'Bill21',\n",
    "       'Deliver']]=df.resample('H').last()[['irregular', 'holiday', 'DeliverD1', 'DeliverD7',\n",
    "       'DeliverD14', 'DeliverD21', 'Bill1', 'Bill7', 'Bill14', 'Bill21',\n",
    "       'Deliver']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fbe5597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>irregular</th>\n",
       "      <th>holiday</th>\n",
       "      <th>y</th>\n",
       "      <th>DeliverD1</th>\n",
       "      <th>DeliverD7</th>\n",
       "      <th>DeliverD14</th>\n",
       "      <th>DeliverD21</th>\n",
       "      <th>Bill1</th>\n",
       "      <th>Bill7</th>\n",
       "      <th>Bill14</th>\n",
       "      <th>Bill21</th>\n",
       "      <th>Deliver</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-02-14 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-14 01:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-14 02:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-14 03:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-02-14 04:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     irregular  holiday    y  DeliverD1  DeliverD7  \\\n",
       "ds                                                                   \n",
       "2004-02-14 00:00:00          0        0  118          0          0   \n",
       "2004-02-14 01:00:00          0        0   70          0          0   \n",
       "2004-02-14 02:00:00          0        0   39          0          0   \n",
       "2004-02-14 03:00:00          0        0   42          0          0   \n",
       "2004-02-14 04:00:00          0        0   16          0          0   \n",
       "\n",
       "                     DeliverD14  DeliverD21  Bill1  Bill7  Bill14  Bill21  \\\n",
       "ds                                                                          \n",
       "2004-02-14 00:00:00           0           0      0      0       0       0   \n",
       "2004-02-14 01:00:00           0           0      0      0       0       0   \n",
       "2004-02-14 02:00:00           0           0      0      0       0       0   \n",
       "2004-02-14 03:00:00           0           0      0      0       0       0   \n",
       "2004-02-14 04:00:00           0           0      0      0       0       0   \n",
       "\n",
       "                     Deliver  \n",
       "ds                            \n",
       "2004-02-14 00:00:00        0  \n",
       "2004-02-14 01:00:00        0  \n",
       "2004-02-14 02:00:00        0  \n",
       "2004-02-14 03:00:00        0  \n",
       "2004-02-14 04:00:00        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSARIMAX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762ab16",
   "metadata": {},
   "source": [
    "# SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad7a8e",
   "metadata": {},
   "source": [
    "First, we set the len_trainset to 20% and split up the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98611e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_trainset=round(0.2*len(dfSARIMAX))\n",
    "train = dfSARIMAX[:len_trainset]\n",
    "test = dfSARIMAX[len_trainset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f3404",
   "metadata": {},
   "source": [
    "The gird search of the model is preformed by the function auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc9ee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 349. MiB for an array with shape (172, 172, 1547) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sxmodel \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_arima\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mirregular\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mholiday\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeliverD1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeliverD7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeliverD14\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeliverD21\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBill1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBill7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBill14\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBill21\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeliver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mstart_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mstart_P\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_Q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmax_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmax_P\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_Q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmax_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mseasonal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                       \u001b[49m\u001b[43md\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                       \u001b[49m\u001b[43merror_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                       \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mstepwise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m sxmodel\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pmdarima\\arima\\auto.py:701\u001b[0m, in \u001b[0;36mauto_arima\u001b[1;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;66;03m# init the stepwise model wrapper\u001b[39;00m\n\u001b[0;32m    670\u001b[0m     search \u001b[38;5;241m=\u001b[39m solvers\u001b[38;5;241m.\u001b[39m_StepwiseFitWrapper(\n\u001b[0;32m    671\u001b[0m         y,\n\u001b[0;32m    672\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msarimax_kwargs,\n\u001b[0;32m    699\u001b[0m     )\n\u001b[1;32m--> 701\u001b[0m sorted_res \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _return_wrapper(sorted_res, return_valid_fits, start, trace)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:286\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper.solve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming stepwise search to minimize \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minformation_criterion)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m# fit a baseline p, d, q model\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# null model with possible constant\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_fit((\u001b[38;5;241m0\u001b[39m, d, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, D, \u001b[38;5;241m0\u001b[39m, m)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:233\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper._do_fit\u001b[1;34m(self, order, seasonal_order, constant)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (order, seasonal_order, constant) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict:\n\u001b[0;32m    229\u001b[0m \n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# increment the number of fits\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 233\u001b[0m     fit, fit_time, new_ic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_arima\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# use the orders as a key to be hashed for\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# the dictionary (pointing to fit)\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict[(order, seasonal_order, constant)] \u001b[38;5;241m=\u001b[39m fit\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:506\u001b[0m, in \u001b[0;36m_fit_candidate_model\u001b[1;34m(y, X, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m fit \u001b[38;5;241m=\u001b[39m ARIMA(order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order,\n\u001b[0;32m    499\u001b[0m             start_params\u001b[38;5;241m=\u001b[39mstart_params, trend\u001b[38;5;241m=\u001b[39mtrend, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    500\u001b[0m             maxiter\u001b[38;5;241m=\u001b[39mmaxiter, suppress_warnings\u001b[38;5;241m=\u001b[39msuppress_warnings,\n\u001b[0;32m    501\u001b[0m             out_of_sample_size\u001b[38;5;241m=\u001b[39mout_of_sample_size, scoring\u001b[38;5;241m=\u001b[39mscoring,\n\u001b[0;32m    502\u001b[0m             scoring_args\u001b[38;5;241m=\u001b[39mscoring_args,\n\u001b[0;32m    503\u001b[0m             with_intercept\u001b[38;5;241m=\u001b[39mwith_intercept, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     fit\u001b[38;5;241m.\u001b[39mfit(y, X\u001b[38;5;241m=\u001b[39mX, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# for non-stationarity errors or singular matrices, return None\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (LinAlgError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m v:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pmdarima\\arima\\arima.py:603\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[1;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[0;32m    600\u001b[0m         X \u001b[38;5;241m=\u001b[39m safe_indexing(X, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_exog \u001b[38;5;241m-\u001b[39m cv))\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# Internal call\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(y, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# now make a forecast if we're validating to compute the\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;66;03m# out-of-sample score\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;66;03m# get the predictions (use self.predict, which calls forecast\u001b[39;00m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;66;03m# from statsmodels internally)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pmdarima\\arima\\arima.py:524\u001b[0m, in \u001b[0;36mARIMA._fit\u001b[1;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    523\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 524\u001b[0m         fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m     fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m _fit_wrapper()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pmdarima\\arima\\arima.py:510\u001b[0m, in \u001b[0;36mARIMA._fit.<locals>._fit_wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m    507\u001b[0m _maxiter \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m, _maxiter)\n\u001b[0;32m    509\u001b[0m disp \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 510\u001b[0m fitted \u001b[38;5;241m=\u001b[39m arima\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    511\u001b[0m     start_params\u001b[38;5;241m=\u001b[39mstart_params,\n\u001b[0;32m    512\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    513\u001b[0m     maxiter\u001b[38;5;241m=\u001b[39m_maxiter,\n\u001b[0;32m    514\u001b[0m     disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args,\n\u001b[0;32m    516\u001b[0m )\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arima, fitted\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:728\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    727\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth\n\u001b[1;32m--> 728\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlefit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincludes_fixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m           \u001b[49m\u001b[43mcov_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_kwds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov_kwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m res\u001b[38;5;241m.\u001b[39mmlefit \u001b[38;5;241m=\u001b[39m mlefit\n\u001b[0;32m    732\u001b[0m res\u001b[38;5;241m.\u001b[39mmle_retvals \u001b[38;5;241m=\u001b[39m mlefit\u001b[38;5;241m.\u001b[39mmle_retvals\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:886\u001b[0m, in \u001b[0;36mMLEModel.smooth\u001b[1;34m(self, params, transformed, includes_fixed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001b[0m\n\u001b[0;32m    883\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Get the state space output\u001b[39;00m\n\u001b[1;32m--> 886\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssm\u001b[38;5;241m.\u001b[39msmooth(complex_step\u001b[38;5;241m=\u001b[39mcomplex_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[38;5;66;03m# Wrap in a results object\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_results(params, result, return_ssm, cov_type,\n\u001b[0;32m    890\u001b[0m                           cov_kwds, results_class,\n\u001b[0;32m    891\u001b[0m                           results_wrapper_class)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_smoother.py:394\u001b[0m, in \u001b[0;36mKalmanSmoother.smooth\u001b[1;34m(self, smoother_output, smooth_method, results, run_filter, prefix, complex_step, update_representation, update_filter, update_smoother, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03mApply the Kalman smoother to the statespace model.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03mSmootherResults object\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# Run the filter\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# Create the results object\u001b[39;00m\n\u001b[0;32m    397\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_class(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:895\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inversion_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m             stability_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, conserve_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m             filter_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loglikelihood_burn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m             complex_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# Initialize the filter\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     prefix, dtype, create_filter, create_statespace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 895\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m     )\n\u001b[0;32m    900\u001b[0m     kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:483\u001b[0m, in \u001b[0;36mKalmanFilter._initialize_filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, tolerance, filter_timing, loglikelihood_burn)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Setup the filter\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix_kalman_filter_map[prefix]\n\u001b[1;32m--> 483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statespaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# Otherwise, update the filter parameters\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m     kalman_filter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_filter.pyx:1720\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_filter.pyx:2131\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.set_filter_method\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstatsmodels\\tsa\\statespace\\_kalman_filter.pyx:1896\u001b[0m, in \u001b[0;36mstatsmodels.tsa.statespace._kalman_filter.dKalmanFilter.allocate_arrays\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 349. MiB for an array with shape (172, 172, 1547) and data type float64"
     ]
    }
   ],
   "source": [
    "sxmodel = pm.auto_arima(train[['y']], exog = train[['irregular', 'holiday', 'DeliverD1', 'DeliverD7', 'DeliverD14', 'DeliverD21', 'Bill1', 'Bill7', 'Bill14', 'Bill21','Deliver']],\n",
    "                       start_p=4, start_q=1,\n",
    "                       start_P=6, start_Q=0,\n",
    "                        max_p=6, max_q=6,\n",
    "                        max_P=6, max_Q=6,\n",
    "                        max_order=6,\n",
    "                       test='adf',\n",
    "                       m=24,seasonal=True,\n",
    "                       d=None, D=1, trace=True,\n",
    "                       error_action='ignore',  \n",
    "                       suppress_warnings=True, \n",
    "                       stepwise=True, max_iter=20)\n",
    "\n",
    "sxmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd80de0",
   "metadata": {},
   "source": [
    "For the in-sample prediction we use the function fittedvalues() note that for the first seasonal cycle these will be off as it uses the values of the previous -24 time steps and for the first cycle these dont exsist and are set to 0. For the computation of the performance these should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d85e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = sxmodel.fittedvalues()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23432507",
   "metadata": {},
   "source": [
    "We use the forecast function to forcast the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e667f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = sxmodel.predict(n_periods=len(test), exog=test[['irregular', 'holiday', 'DeliverD1', 'DeliverD7',\n",
    "       'DeliverD14', 'DeliverD21', 'Bill1', 'Bill7', 'Bill14', 'Bill21',\n",
    "       'Deliver']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5e2a5",
   "metadata": {},
   "source": [
    "Then we put them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ded2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.concat([pred, forecast])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa22a79",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train = df['y'][:len_trainset] #actual values of y for training set\n",
    "y_true_test = df['y'][len_trainset:]  #actual values of y for test set\n",
    "y_pred_train = prediction[:len_trainset] #predicted values of y for training set\n",
    "y_pred_test = prediction[len_trainset:]  #predicted values of y for test set\n",
    "\n",
    "MAEtrain = mean_absolute_error(y_true_train, y_pred_train) #in-sample MAE\n",
    "MAEtest = mean_absolute_error(y_true_test, y_pred_test)    #out-of-sample MAE\n",
    "\n",
    "print('train MAE', MAEtrain)\n",
    "print('test MAE', MAEtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True, constrained_layout=True, figsize=(13, 3))\n",
    "\n",
    "ax.set_title('SARIMAX')\n",
    "ax.plot(np.asarray(results_arima.ds, dtype='datetime64[s]'), results_arima.y, color= '#555B6E', label = 'Actual')\n",
    "# Plot the predicted values\n",
    "ax.plot(np.asarray(results_arima.ds, dtype='datetime64[s]'), results_arima.Forecast, label = 'Prediction', alpha=0.9, color= '#F3B768')\n",
    "ax.axvline(x=np.asarray(results_arima.ds, dtype='datetime64[s]')[len_trainset], color='k', linestyle='--', alpha=0.7)\n",
    "ax.margins(x=0.01)\n",
    "ax.margins(y=0.02)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "fig.supxlabel('Date')\n",
    "fig.supylabel('Number of calls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a93c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom1 = 50 #amount of observation from the train set you see\n",
    "zoom2 = 400  #amount of observation from test you see\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True,  constrained_layout=True, figsize=(13, 3))\n",
    "\n",
    "ax.set_title('SARIMAX')\n",
    "ax.plot(np.asarray(results_arima.ds, dtype='datetime64[s]')[len_trainset-zoom1:len_trainset+zoom2], results_arima.y[len_trainset-zoom1:len_trainset+zoom2], color= '#555B6E', label = 'Actual')\n",
    "# Plot the predicted values\n",
    "ax.plot(np.asarray(results_arima.ds, dtype='datetime64[s]')[len_trainset-zoom1:len_trainset+zoom2], results_arima.Forecast[len_trainset-zoom1:len_trainset+zoom2], label = 'Prediction', alpha=0.9, color= '#F3B768')\n",
    "ax.axvline(x=np.asarray(results_arima.ds, dtype='datetime64[s]')[len_trainset], color='k', linestyle='--', alpha=0.7)\n",
    "ax.margins(x=0.01)\n",
    "ax.margins(y=0.02)\n",
    "ax.legend(loc=\"upper left\")\n",
    "fig.supxlabel('Date')\n",
    "fig.supylabel('Number of calls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
